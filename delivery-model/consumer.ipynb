{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cec221a",
   "metadata": {},
   "source": [
    "## Food Delivery Time Prediction Model\n",
    "\n",
    "You will train a ML model using an LSTM neural network model for the food delivery time prediction. It constructs a neural network using Keras for a food delivery system, designed to predict delivery times based on inputs like age, rating, and distance. :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from kafka import KafkaConsumer\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (3, 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', run_eagerly=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ea5bb",
   "metadata": {},
   "source": [
    "It starts with a Sequential model, indicating a linear stack of layers, followed by two LSTM (Long Short-Term Memory) layers - ideal for sequential data processing. \n",
    "\n",
    "Followed by two Dense layers: the first with 25 neurons for further processing, and the second with a single neuron to output the predicted delivery time. \n",
    "\n",
    "The model uses the 'adam' optimizer and 'mean_squared_error' as the loss function, suitable for regression tasks like predicting time. \n",
    "\n",
    "Finally, model.summary() provides a structured overview of this neural network architecture.\n",
    "\n",
    "## Continuous Data Training in Machine Learning\n",
    "\n",
    "You will now start the training by running the next snippet, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_train_ds = tfio.experimental.streaming.KafkaBatchIODataset(\n",
    "    topics=[\"model-data\"],\n",
    "    group_id=\"testzo\",\n",
    "    servers=\"redpanda-0:9092,redpanda-1:9092,redpanda-2:9092\",\n",
    "    stream_timeout=10000,\n",
    "    configuration=[\n",
    "        \"session.timeout.ms=7000\",\n",
    "        \"max.poll.interval.ms=8000\",\n",
    "        \"auto.offset.reset=earliest\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def decode_kafka_online_item(raw_message, raw_key):\n",
    "    message = tf.io.decode_csv(raw_message, [[0.0] for i in range(3)])\n",
    "    key = tf.strings.to_number(raw_key)\n",
    "    return (message, key)\n",
    "  \n",
    "batch_size = 20\n",
    "for single_ds in online_train_ds:\n",
    "    if len(single_ds) >= batch_size:\n",
    "        single_ds = single_ds.shuffle(buffer_size=batch_size)\n",
    "        single_ds = single_ds.map(decode_kafka_online_item)\n",
    "        single_ds = single_ds.batch(batch_size)\n",
    "    \n",
    "        model.fit(single_ds, epochs=1)\n",
    "        tf.keras.models.save_model(model, \"./time_prediction_model\")\n",
    "    else:\n",
    "        print(\"Not enough data in the dataset. Skipping model fitting.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774acb5",
   "metadata": {},
   "source": [
    "The above machine learning code leverages **TensorFlow** I/Oâ€™s __KafkaBatchIODataset__ to stream data directly from Redpanda topics into a TensorFlow dataset. This dataset is configured to ingest data from the 'model-data' topic on a Redpanda cluster. The main processing loop handles data in batches: it accumulates messages until there are enough to constitute a batch (set to a size of 20), then shuffles and decode batch before using it for training. Subsequently, the model is trained for one epoch with each batch and then saved.\n",
    "\n",
    "This ongoing training loop enables the model to dynamically learn from a continuous stream of real-time food delivery data. Such an approach ensures that applications utilizing this model can provide predictions that are consistently updated with the most recent data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
